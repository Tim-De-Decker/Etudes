{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ce notebook propose une application en NLP (analyse de sentiment binaire) avec deux modèles relevant respectivement du machine learning et du deep learning: le boosting de gradient et une variante de réseau de neurones récurrent. L'intérêt de cet exercice est entre autres d'illustrer sommairement deux aproches du prétraitement des données textuelles._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise le dataset __IMDb__ qui recense 50000 critiques de films et de séries (variable _review_), chacune associée à un label indiquant le sentiment général exprimé, positif ou négatif (variable _sentiment_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = pd.read_csv('Machine_Learning/imdb.csv')\n",
    "print(imdb.shape)\n",
    "imdb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des features et de la cible\n",
    "X, y = imdb.iloc[:,0].to_numpy(), imdb.iloc[:,1].to_numpy()\n",
    "\n",
    "# Recodage de la cible qualitative binaire\n",
    "y[y=='positive'] = 1\n",
    "y[y=='negative'] = 0\n",
    "y = y.astype('int')\n",
    "\n",
    "# Dissociation de l'ensemble d'apprentissage (80%) et de l'ensemble de test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 1 : Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour recourir au _gradient boosting_, il faut d'abord transformer nos données de manière à les rendre utilisables par l'algorithme.\n",
    "\n",
    "On utilise ici la fonction `CountVectorizer()` afin d'opérer les transformations suivantes :\n",
    "* chaque document (chaque critique) est _tokenisé_, c'est-à-dire découpé en sous-chaînes de caractères qui peuvent être des mots entiers comme ici, des fractions ou des groupes de mots de longueur définie ;\n",
    "* les _tokens_ obtenus à partir des documents de l'ensemble d'apprentissage sont ensuite référencés dans un dictionnaire et identifiés par un entier unique ;\n",
    "* chaque document est alors transformé en vecteur de même longueur que le dictionnaire : la valeur d'indice $i$ du vecteur correspond au nombre d'occurrences du mot identifié par la valeur $i$ dans le dictionnaire.\n",
    "\n",
    "La longueur du dictionnaire peut être contrôlée pour améliorer les résultats et réduire la taille des documents vectorisés : en plus de la liste par défaut de ___stop words___ qui en sont exclus (les mots les plus fréquents de la langue choisie : les articles par exemple), on peut limiter le dictionnaire aux $n$ mots les plus fréquents parmi les documents et/ou supprimer les mots présents dans plus de 50% d'entre eux.\n",
    "\n",
    "Cette suite d'opérations revient à appliquer l'algorithme dit du __sac de mots (_bag of words_)__ : la représentation obtenue est relativement pauvre en signification puisqu'on perd le contexte d'utilisation des _tokens_ mais elle est facile à implémenter et donne des résultats satisfaisants pour des tâches simples de classification textuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On initialise un objet CountVectorizer qui ignore les mots présents dans plus de 50% des documents\n",
    "# et qui sélectionne les 5000 mots les plus fréquents parmi ceux qui restent\n",
    "vectorizer = CountVectorizer(max_features=5000, max_df=.5)\n",
    "\n",
    "# Ajustement sur les données d'apprentissage (création du dictionnaire) et transformation\n",
    "X_trainV = vectorizer.fit_transform(X_train)\n",
    "X_testV = vectorizer.transform(X_test)\n",
    "\n",
    "# L'ensemble d'apprentissage devient une matrice contenant 40000 lignes (observations)\n",
    "# et 5000 colonnes (une par mot du dictionnaire)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What a terrible film.<br /><br />It starts well, with the title sequence, but that's about as good as it gets.<br /><br />The movie is something about rats turning into monsters and going on a killing spree. The acting isn't so much poor, but the script is pointless and the film isn't even scary despite the atmospheric music.<br /><br />It really is amazing that some group cobbled together this bag of rubbish and thought it would make a good film.<br /><br />It isn't a good film. It's trash, and I urge you not to waste a minute of your life on it! One out of ten.\""
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple de document\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Représentation \"sac de mots\"\n",
    "X_trainV.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['about', 'acting', 'amazing', 'atmospheric', 'bag', 'despite',\n",
       "       'even', 'gets', 'going', 'good', 'group', 'into', 'isn', 'killing',\n",
       "       'life', 'make', 'minute', 'monsters', 'much', 'music', 'out',\n",
       "       'pointless', 'poor', 'really', 'rubbish', 'scary', 'script',\n",
       "       'sequence', 'so', 'some', 'something', 'starts', 'ten', 'terrible',\n",
       "       'thought', 'title', 'together', 'trash', 'turning', 'urge',\n",
       "       'waste', 'well', 'what', 'would', 'your'], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Illustration des tokens obtenus pour le document en exemple\n",
    "vectorizer.get_feature_names_out()[X_trainV.toarray()[0]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fréquence de chaque token identifié\n",
    "X_trainV[0].toarray()[X_trainV[0].toarray()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec cette nouvelle représentation des données, on peut ajuster un modèle de _gradient boosting_. \n",
    "\n",
    "Pour rappel, son algorithme se résume à :\n",
    "* partir d'une prédiction aléatoire pour la variable cible ;\n",
    "* ajuster un arbre de décision pour retrouver l'erreur obtenue à partir des variables explicatives ;\n",
    "* ajouter au modèle de base la prédiction de l'arbre de décision réduite d'un facteur appelé taux d'apprentissage ;\n",
    "* mettre à jour l'erreur ;\n",
    "* ajuster un nouvel arbre sur l'erreur mise à jour et ainsi de suite jusqu'à atteindre un critère d'arrêt (avoir créé $x$ arbres par exemple).\n",
    "\n",
    "Le modèle présente donc 3 hyperparamètres : le nombre d'estimateurs à créer, le taux d'apprentissage et la profondeur maximale de chaque arbre. On les optimise par __cross-validation__ ; les résultats sont présentés ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy moyenne maximale : 0.8704000000000001 \n",
      "Atteinte pour n_estimators = 200, learning_rate = 0.5 et max_depth = 3\n"
     ]
    }
   ],
   "source": [
    "# Le code est neutralisé pour ne pas ralentir les exécutions ultérieures du notebook\n",
    "\n",
    "# grid = {'n_estimators': [100, 200],\n",
    "#        'learning_rate' : [0.5, 1],\n",
    "#        'max_depth' : [1, 3, 5]}\n",
    "\n",
    "# rfCross = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "#                          param_grid=grid,\n",
    "#                          scoring='accuracy',\n",
    "#                          cv=10\n",
    "#                         )\n",
    "\n",
    "# rfCross.fit(X_trainV, y_train)\n",
    "\n",
    "# print(f\"\\nAccuracy moyenne maximale : {rfCross.best_score_} \\nAtteinte pour n_estimators = {rfCross.best_params_['n_estimators']}, learning_rate = {rfCross.best_params_['learning_rate']} et max_depth = {rfCross.best_params_['max_depth']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=200,\n",
    "                                learning_rate=0.5,\n",
    "                                max_depth=3,\n",
    "                                random_state=42)\n",
    "clf.fit(X_trainV, y_train)\n",
    "y_pred = clf.predict(X_testV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      5108\n",
      "           1       0.85      0.89      0.87      4892\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec les meilleurs paramètres obtenus, on atteint un score d'exactitude de 87 % sur l'ensemble de test, c'est à dire qu'on prédit correctement le sentiment positif ou négatif des critiques dans 87 % des cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 2 : réseau de neurones récurrent (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras import Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données IMDb déjà tokenisées peuvent être importées directement via _keras_. On limite le dictionnaire aux 5000 mots les plus fréquents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la différence du modèle précédent, la structure de réseau de neurones récurrent permet de traiter les données de manière séquentielle : les mots sont ainsi traités par ordre d'apparition dans le document concerné. Il devient ainsi possible de tenir compte du contexte dans lequel ils sont employés.\n",
    "\n",
    "Il faut cependant que les données fournies en entrée du réseau soient de même format : après avoir remarqué que la grande majorité des commentaires contiennent moins de 500 mots, on entreprend de raccourcir ou prolonger les séquences (quitte à les combler par des valeurs neutres) afin qu'elles contiennent exactement 500 valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATtklEQVR4nO3df4zcd53f8eer9mGld5iGZEGu7asNmJOc6M7glS8VBdGmvZhQnUNFWuePi6tGMkSJdOhaqc7xB1ElS+RaLlJ0xSfTREkQJKSEKJYgLWk4XVTJJLfhTGwn+LImvstiy95rELjicGvz7h/zmetkPd71zqx37d3nQ/pqvvP+fj7f+XxmiF/7/TFDqgpJkv7OQg9AknR5MBAkSYCBIElqDARJEmAgSJKa5Qs9gEFde+21tW7duoUehiRdUV566aW/rqqRftuu2EBYt24dY2NjCz0MSbqiJPnLC23zlJEkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIk4CICIclDSU4lOdRT+1qSA205luRAq69L8jc92/64p8/mJAeTjCd5IElafUXb33iSF5Ksm/tpSpJmcjFHCA8DW3sLVfWvqmpTVW0CngS+0bP5aHdbVX26p74H2AlsaEt3n3cAP66q9wH3A/cNMhFJ0nBm/KZyVT1/ob/a21/5/xL4J9PtI8kqYGVV7W/PHwVuAZ4BtgH3tqZfB/4oSeoS/j/3rNv1zUu16xkd+/zHF+y1JWk6w15D+DBwsqpe66mtT/LnSf40yYdbbTUw0dNmotW6294AqKqzwE+Aa/q9WJKdScaSjE1OTg45dElSr2ED4TbgsZ7nJ4BfraoPAL8HfDXJSiB9+naPAKbb9tZi1d6qGq2q0ZGRvr/NJEka0MA/bpdkOfAvgM3dWlWdAc609ZeSHAXeT+eIYE1P9zXA8bY+AawFJto+3wG8Oei4JEmDGeYI4Z8CP6iqvz0VlGQkybK2/h46F49/WFUngNNJbmjXHW4Hnm7d9gE72vonge9cyusHkqT+Lua208eA/cCvJZlIckfbtJ23ni4C+AjwcpLv07lA/Omq6v61fyfwX4Bx4CidC8oADwLXJBmnc5pp1xDzkSQN6GLuMrrtAvV/3af2JJ3bUPu1HwOu71P/OXDrTOOQJF1aflNZkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqZkxEJI8lORUkkM9tXuT/CjJgbbc3LPtniTjSY4kuamnvjnJwbbtgSRp9RVJvtbqLyRZN8dzlCRdhIs5QngY2Nqnfn9VbWrLtwCSbAS2A9e1Pl9Msqy13wPsBDa0pbvPO4AfV9X7gPuB+waciyRpCDMGQlU9D7x5kfvbBjxeVWeq6nVgHNiSZBWwsqr2V1UBjwK39PR5pK1/Hbixe/QgSZo/w1xDuDvJy+2U0tWtthp4o6fNRKutbutT62/pU1VngZ8A1/R7wSQ7k4wlGZucnBxi6JKkqQYNhD3Ae4FNwAngC63e7y/7mqY+XZ/zi1V7q2q0qkZHRkZmNWBJ0vQGCoSqOllV56rqF8CXgC1t0wSwtqfpGuB4q6/pU39LnyTLgXdw8aeoJElzZKBAaNcEuj4BdO9A2gdsb3cOradz8fjFqjoBnE5yQ7s+cDvwdE+fHW39k8B32nUGSdI8Wj5TgySPAR8Frk0yAXwO+GiSTXRO7RwDPgVQVYeTPAG8ApwF7qqqc21Xd9K5Y+kq4Jm2ADwIfDnJOJ0jg+1zMC9J0izNGAhVdVuf8oPTtN8N7O5THwOu71P/OXDrTOOQJF1aflNZkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEnARQRCkoeSnEpyqKf2H5P8IMnLSZ5K8vdafV2Sv0lyoC1/3NNnc5KDScaTPJAkrb4iydda/YUk6+Z+mpKkmVzMEcLDwNYptWeB66vq14G/AO7p2Xa0qja15dM99T3ATmBDW7r7vAP4cVW9D7gfuG/Ws5AkDW3GQKiq54E3p9S+XVVn29PvAmum20eSVcDKqtpfVQU8CtzSNm8DHmnrXwdu7B49SJLmz1xcQ/g3wDM9z9cn+fMkf5rkw622GpjoaTPRat1tbwC0kPkJcE2/F0qyM8lYkrHJyck5GLokqWuoQEjyWeAs8JVWOgH8alV9APg94KtJVgL9/uKv7m6m2fbWYtXeqhqtqtGRkZFhhi5JmmL5oB2T7AD+OXBjOw1EVZ0BzrT1l5IcBd5P54ig97TSGuB4W58A1gITSZYD72DKKSpJ0qU30BFCkq3Avwd+u6p+1lMfSbKsrb+HzsXjH1bVCeB0khva9YHbgadbt33Ajrb+SeA73YCRJM2fGY8QkjwGfBS4NskE8Dk6dxWtAJ5t13+/2+4o+gjwH5KcBc4Bn66q7l/7d9K5Y+kqOtccutcdHgS+nGSczpHB9jmZmSRpVmYMhKq6rU/5wQu0fRJ48gLbxoDr+9R/Dtw60zgkSZeW31SWJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJamYMhCQPJTmV5FBP7Z1Jnk3yWnu8umfbPUnGkxxJclNPfXOSg23bA0nS6iuSfK3VX0iybo7nKEm6CBdzhPAwsHVKbRfwXFVtAJ5rz0myEdgOXNf6fDHJstZnD7AT2NCW7j7vAH5cVe8D7gfuG3QykqTBzRgIVfU88OaU8jbgkbb+CHBLT/3xqjpTVa8D48CWJKuAlVW1v6oKeHRKn+6+vg7c2D16kCTNn0GvIby7qk4AtMd3tfpq4I2edhOttrqtT62/pU9VnQV+AlzT70WT7EwylmRscnJywKFLkvqZ64vK/f6yr2nq0/U5v1i1t6pGq2p0ZGRkwCFKkvoZNBBOttNAtMdTrT4BrO1ptwY43upr+tTf0ifJcuAdnH+KSpJ0iQ0aCPuAHW19B/B0T317u3NoPZ2Lxy+200qnk9zQrg/cPqVPd1+fBL7TrjNIkubR8pkaJHkM+ChwbZIJ4HPA54EnktwB/BVwK0BVHU7yBPAKcBa4q6rOtV3dSeeOpauAZ9oC8CDw5STjdI4Mts/JzCRJszJjIFTVbRfYdOMF2u8GdvepjwHX96n/nBYokqSF4zeVJUmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkpqBAyHJryU50LP8NMlnktyb5Ec99Zt7+tyTZDzJkSQ39dQ3JznYtj2QJMNOTJI0OwMHQlUdqapNVbUJ2Az8DHiqbb6/u62qvgWQZCOwHbgO2Ap8Mcmy1n4PsBPY0Jatg45LkjSYuTpldCNwtKr+cpo224DHq+pMVb0OjANbkqwCVlbV/qoq4FHgljkalyTpIs1VIGwHHut5fneSl5M8lOTqVlsNvNHTZqLVVrf1qXVJ0jwaOhCSvA34beC/ttIe4L3AJuAE8IVu0z7da5p6v9famWQsydjk5OQww5YkTTEXRwgfA75XVScBqupkVZ2rql8AXwK2tHYTwNqefmuA462+pk/9PFW1t6pGq2p0ZGRkDoYuSeqai0C4jZ7TRe2aQNcngENtfR+wPcmKJOvpXDx+sapOAKeT3NDuLrodeHoOxiVJmoXlw3RO8neBfwZ8qqf8B0k20Tntc6y7raoOJ3kCeAU4C9xVVedanzuBh4GrgGfaIkmaR0MFQlX9DLhmSu13pmm/G9jdpz4GXD/MWCRJw/GbypIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEnN8oUewFKzbtc3F+R1j33+4wvyupKuHEMdISQ5luRgkgNJxlrtnUmeTfJae7y6p/09ScaTHElyU099c9vPeJIHkmSYcUmSZm8uThn946raVFWj7fku4Lmq2gA8156TZCOwHbgO2Ap8Mcmy1mcPsBPY0JatczAuSdIsXIprCNuAR9r6I8AtPfXHq+pMVb0OjANbkqwCVlbV/qoq4NGePpKkeTJsIBTw7SQvJdnZau+uqhMA7fFdrb4aeKOn70SrrW7rU+vnSbIzyViSscnJySGHLknqNexF5Q9V1fEk7wKeTfKDadr2uy5Q09TPL1btBfYCjI6O9m0jSRrMUEcIVXW8PZ4CngK2ACfbaSDa46nWfAJY29N9DXC81df0qUuS5tHAgZDkl5O8vbsO/BZwCNgH7GjNdgBPt/V9wPYkK5Ksp3Px+MV2Wul0khva3UW39/SRJM2TYU4ZvRt4qt0huhz4alX9tyR/BjyR5A7gr4BbAarqcJIngFeAs8BdVXWu7etO4GHgKuCZtkiS5tHAgVBVPwR+o0/9fwE3XqDPbmB3n/oYcP2gY5EkDc+frpAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqBg6EJGuT/EmSV5McTvK7rX5vkh8lOdCWm3v63JNkPMmRJDf11DcnOdi2PZAkw01LkjRby4foexb4t1X1vSRvB15K8mzbdn9V/afexkk2AtuB64C/D/yPJO+vqnPAHmAn8F3gW8BW4JkhxiZJmqWBjxCq6kRVfa+tnwZeBVZP02Ub8HhVnamq14FxYEuSVcDKqtpfVQU8Ctwy6LgkSYOZk2sISdYBHwBeaKW7k7yc5KEkV7faauCNnm4Trba6rU+t93udnUnGkoxNTk7OxdAlSc3QgZDkV4Angc9U1U/pnP55L7AJOAF8odu0T/eapn5+sWpvVY1W1ejIyMiwQ5ck9RgqEJL8Ep0w+EpVfQOgqk5W1bmq+gXwJWBLaz4BrO3pvgY43upr+tQlSfNomLuMAjwIvFpVf9hTX9XT7BPAoba+D9ieZEWS9cAG4MWqOgGcTnJD2+ftwNODjkuSNJhh7jL6EPA7wMEkB1rt94Hbkmyic9rnGPApgKo6nOQJ4BU6dyjd1e4wArgTeBi4is7dRd5hJEnzbOBAqKr/Sf/z/9+aps9uYHef+hhw/aBjkSQNz28qS5IAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQKG+2KariDrdn1zwV772Oc/vmCvLenieYQgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVLjT1fokluon83wJzOk2fEIQZIEGAiSpOayCYQkW5McSTKeZNdCj0eSlprLIhCSLAP+M/AxYCNwW5KNCzsqSVpaLpeLyluA8ar6IUCSx4FtwCsLOipd0byYLc3O5RIIq4E3ep5PAL85tVGSncDO9vR/JzkywGtdC/z1AP2uZEtxzrBA88598/2Kb7EUP2vnPDv/4EIbLpdASJ9anVeo2gvsHeqFkrGqGh1mH1eapThnWJrzds5Lw6Wa82VxDYHOEcHanudrgOMLNBZJWpIul0D4M2BDkvVJ3gZsB/Yt8JgkaUm5LE4ZVdXZJHcD/x1YBjxUVYcv0csNdcrpCrUU5wxLc97OeWm4JHNO1Xmn6iVJS9DlcspIkrTADARJErCEAmEx/zRGkmNJDiY5kGSs1d6Z5Nkkr7XHq3va39PehyNJblq4kc9OkoeSnEpyqKc263km2dzer/EkDyTpd9vzZeECc743yY/a530gyc092xbDnNcm+ZMkryY5nOR3W33RftbTzHl+P+uqWvQLnQvVR4H3AG8Dvg9sXOhxzeH8jgHXTqn9AbCrre8C7mvrG9v8VwDr2/uybKHncJHz/AjwQeDQMPMEXgT+IZ3vvzwDfGyh5zbLOd8L/Ls+bRfLnFcBH2zrbwf+os1t0X7W08x5Xj/rpXKE8Lc/jVFV/wfo/jTGYrYNeKStPwLc0lN/vKrOVNXrwDid9+eyV1XPA29OKc9qnklWASuran91/ut5tKfPZecCc76QxTLnE1X1vbZ+GniVzq8ZLNrPepo5X8glmfNSCYR+P40x3Zt9pSng20leaj/vAfDuqjoBnf+xAe9q9cX2Xsx2nqvb+tT6lebuJC+3U0rdUyeLbs5J1gEfAF5giXzWU+YM8/hZL5VAuKifxriCfaiqPkjn12LvSvKRadou9vei60LzXAzz3wO8F9gEnAC+0OqLas5JfgV4EvhMVf10uqZ9alfkvPvMeV4/66USCIv6pzGq6nh7PAU8RecU0Ml2+Eh7PNWaL7b3YrbznGjrU+tXjKo6WVXnquoXwJf4/6f8Fs2ck/wSnX8Yv1JV32jlRf1Z95vzfH/WSyUQFu1PYyT55SRv764DvwUcojO/Ha3ZDuDptr4P2J5kRZL1wAY6F6GuVLOaZzvVcDrJDe3ui9t7+lwRuv8oNp+g83nDIplzG+ODwKtV9Yc9mxbtZ32hOc/7Z73QV9fnawFupnPl/ijw2YUezxzO6z107jb4PnC4OzfgGuA54LX2+M6ePp9t78MRLtO7Li4w18foHDb/Xzp/Cd0xyDyB0fYf1lHgj2jf2L8clwvM+cvAQeDl9g/DqkU2539E5zTHy8CBtty8mD/raeY8r5+1P10hSQKWzikjSdIMDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKn5f2sClWmDfFjKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in X_train])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=500)\n",
    "X_test = pad_sequences(X_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En termes de représentation des données, on incorpore cette fois à notre réseau une couche dite d'_embedding_. L'___embedding___ ou \"plongement lexical\" consiste à décrire chaque mot de la séquence par un vecteur de réels plutôt qu'un vecteur _one-hot_ de la taille du dictionnaire. L'intérêt de cette technique est double puisqu'en plus de réduire la taille des données, elle permet d'identifier par des vecteurs proches des mots employés dans des contextes similaires. Les vecteurs associés à chaque mot sont déterminés par rétro-propagation de l'erreur au cours de l'ajustement du réseau.\n",
    "\n",
    "On utilise de surcroît une forme particulière de réseau récurrent, qualifiée de ___long-short term memory___ : en plus d'inclure l'output $n-1$ au calcul de l'output $n$ à partir de l'input $n$ (mémoire de court terme), un réseau LSTM intègre un reliquat des outputs plus lointains (mémoire de long terme). Là encore, cette architecture aide à tenir compte de la séquence dans son ensemble et du sens porté par la phrase ou le document entier, au-delà du simple mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(layers = [Embedding(input_dim=5000, output_dim=20),\n",
    "                             LSTM(units=20),\n",
    "                             Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 29s 109ms/step - loss: 0.4988 - acc: 0.7511 - val_loss: 0.3128 - val_acc: 0.8738\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 27s 108ms/step - loss: 0.2737 - acc: 0.8939 - val_loss: 0.2950 - val_acc: 0.8764\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 27s 108ms/step - loss: 0.2240 - acc: 0.9173 - val_loss: 0.3012 - val_acc: 0.8817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e0026e64f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          epochs=3, \n",
    "          batch_size=100, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre petit réseau atteint une exactitude sur les données de test similaire à celle du modèle précédent, autour de 87-88%. Avec une architecture plus élaborée cependant, il serait possible de dépasser les 95%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
